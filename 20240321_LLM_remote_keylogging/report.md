# What Was Your Prompt? A Remote Keylogging Attack on AI Assistants

## 論文
[What Was Your Prompt? A Remote Keylogging Attack on AI Assistants](https://arxiv.org/abs/2403.09751)

---

## 要約（GPT-4)
この文書は、AIアシスタントに対する新たなサイドチャネル攻撃を明らかにする論文です。著者たちは、特にOpenAIやMicrosoftなどのベンダーが提供するサービスを対象に、AIアシスタントがWeb上で暗号化された応答を送信する際に使用されるトークン長のサイドチャネルを特定しました。このサイドチャネルを利用して、攻撃者がネットワーク上で暗号化された応答を読み取ることができることを発見しました。

具体的には、AIアシスタントからの応答がトークン（言葉に似た単位）のシーケンスとして生成され、各トークンが生成されるごとにユーザーに送信されるプロセスを利用します。このプロセスは暗号化されていますが、パケットのサイズからトークンの長さを推測できるため、機密性の高い情報が漏洩する可能性があります。

研究者たちは、このサイドチャネルを利用してトークンの長さのシーケンスから元のテキストを再構築する「トークン推論攻撃」を提案しました。大規模言語モデル（LLM）を用いてトークンのシーケンスを解釈し、コンテキストを考慮して探索範囲を絞り込むことにより、攻撃の成功率を高めています。この攻撃により、AIアシスタントの応答の約29%を正確に再構築し、55%からそのトピックを推測することに成功しました。

論文では、この脆弱性を解消するための対策も議論されており、AIアシスタントのセキュリティを強化するための指針を提供しています。

---

## 理解したこと
 - AIアシスタント（ChatGPT、BingAIなど）はUX向上のためにリアルタイム応答を行う。その際に暗号文と共に生成したトークンをサイドチャネルを用いて送信する。
 - サイドチャネルのトークン長とメッセージサイズから、ユーザーとAIアシスタントとの会話内容もしくはトピックを特定できる。
 - 上記だけでは単語の組み合わせが無数に存在し特定は難しいが、段落を特定する技術やAIアシスタントの回答のクセ、LLMにAIアシスタントの回答を教師あり学習でファインチューニングすることでこの攻撃手法の精度を向上させている。
 - 前提としてAIアシスタントの解答のクセがあること。また、攻撃者がユーザーとAIアシスタントとの通信を傍受できる環境にあることが挙げられる。
 - 一般名詞に関しては推論できないもしくは類義語に置き換えられる場合が多いが、長い固有名詞（Yellowstone National Park, The Road Not Takenなど）に関しては文脈と関係なく完璧に推論されている。
 - AIアシスタントを提供する側の対策としてはサイドチャネルでのトークン長にランダムなパディングを組み込むことやトークンをグループ化すること、応答をバッチ処理に変更することなどで脆弱性を軽減できる。

---

## 疑問
 - AIアシスタントの回答のクセは質問事項を繰り返して出力するというところに焦点があたっているのだろうか？
 - 規則性のある言語全てに当てはまるのだろうか？日本語は少なくとも当てはまらなそう…