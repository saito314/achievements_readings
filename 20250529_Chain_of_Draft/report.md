# 論文閲覧: 「Chain of Draft: Thinking Faster by Writing Less」

## 概要
大規模言語モデル（LLMs）は、Chain-of-Thought（CoT）プロンプティングのようなステップバイステップの詳細な推論メカニズムを用いることで、複雑な推論タスクを解決する上で顕著な性能を示している．しかし、人間は通常、重要な情報だけを簡潔にメモすることで、より効率的な戦略を用いている．本研究では、LLMがタスクを解決する際に、最小限かつ有益な中間推論を生成する新たなパラダイム「Chain of Draft（CoD）」を提案する．冗長性を減らし、重要な洞察に焦点を当てることで、CoDはCoTと同等またはそれ以上の精度を維持しながら、トークン使用量を最大92%削減した．

## はじめに
OpenAIのo1やDeepSeekのR1などの進展により、LLMはCoTなどの技術を使って複雑なタスクにおいて高精度を実現している．CoTは人間の推論を模倣して詳細にステップを分解しますが、冗長であり、推論過程のトークン数とレイテンシ（応答時間）が増大する．これに対し、人間は重要な中間情報を簡潔に書き出すことで、効率的に思考を進める．

そこで、我々は「Chain of Draft」という新しい戦略を提案する．これは人間の思考スタイルを模して、簡潔な中間ステップを生成することにより、効率性を重視しながらも高精度を維持するものである．

## 関連研究
- Structured Reasoning Frameworks for LLMs 

CoTやツリー・グラフ型推論、自己整合性CoT、ReActなどがLLM推論精度を改善．

- LLM Inference Latency Reduction

Skeleton-of-Thought、Draft&Verify、Coconutなどが提案されているが、Chain of Draftのような柔軟性や汎用性には欠ける．

## Chain of Draftプロンプティング
CoDは、1ステップにつき5語以内という制限を設けることにより、推論の各ステップを簡潔に保ちます（制限は厳密には強制されない）．以下に各手法の例を示す：

Q: 20個のキャンディーがあり、12個になった．いくつあげた？

- 標準プロンプティング：

A: 8（説明なし）

- Chain-of-Thought：

A: 「最初に20個...今は12個...差分は8個」など、詳細なステップ付き

- Chain-of-Draft：

A: 「20 - x = 12; x = 8」← 簡潔な式のみ

## 実験
GPT-4oとClaude 3.5 Sonnetを使用．以下の比較結果が示されている：

|モデル|プロンプト|精度|トークン数|レイテンシ|
|---|---|---|---|---|
|GPT-4o|CoT|95.4%|205|4.2秒|
|GPT-4o|CoD|91.1%|44|1.0秒|
|Claude|CoT|95.8%|190|3.1秒|
|Claude|CoD|91.4%|40|1.6秒|

## 制限事項
- ゼロショットでは不安定

特にClaude3.5において、Few-shotを活用するなどいくつかの例を提示しないとCoDの効果は低下する．

- 小規模モデルでの性能差

3B以下のモデルでは、CoTの方が依然優位であり、CoD形式での追加学習が有効と考えられる．

## 議論と今後の展望
- CoDは推論精度を維持しながら、トークン効率とレイテンシを大幅に改善する．
- 今後は、CoDと他の手法（並列推論や多段階検証など）とのハイブリッド戦略や、少トークン推論形式によるLLMトレーニングの新方針などが研究の方向性となるだろう．


-----
## 理解・納得したこと
- プロンプトエンジニアリングをするなかで、トークン数の大きさはビジネス（特にランニングコスト）というところで大きな要因になりえるため、CoDプロンプティングはLLMsを用いるシステムに重要だと考える．
- LLMsはリアルタイム性が求められるシステムとの相性が悪いが、CoDプロンプティングを使うことによりどのハードルが下がると考えられる．

## 疑問
- Few_shotを必要とする場合、トークン数が増加すると考えられるが例を提示する数が標準プロンプトと比べて減少するのだろうか．
- 91%と95%の精度は同等というのだろうか．少なくとも機械学習モデルの精度において90%以上の4%の際は同等とは言わない可能性が高い．
- OpenAI o1シリーズはCoTプロンプティングのように段階的に推論することが知られているが、そのモデルにCoDプロンプティングは有効なのだろうか．